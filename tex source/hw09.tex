\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage{hyperref}
\usepackage{xypic}
\usepackage{txfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amscd}
\usepackage{amsmath, mathtools,amssymb}
\usepackage{amsfonts,semantic,colortbl,mathrsfs,stmaryrd}
\usepackage{enumerate}
\usepackage{multirow}
\usepackage{graphicx}
\date{Feb 14, 2012}
\newtheorem{thm}{Theorem}
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{fact}[thm]{Fact}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{eg}{Example}
\newtheorem{hw}{Problem}
\newcommand{\xor}{\otimes}
\newenvironment{sol}
  {\par\vspace{3mm}\noindent{\it Solution}.}
  {\qed}
\begin{document}
\begin{center}
{\LARGE\bf Homework 9}\\
\vspace{2mm}
\end{center}

\begin{hw}
What is the expected number of trees with $k$ vertices in $G\in \mathcal{G}(n,p)$?
\end{hw}
\begin{sol}
	According to \emph{Caleyâ€™s formula}, the number of different trees with $k$ vertices is $k^{k-2}$. By the linearity of expectation, we have the expected number of trees with $k$ vertices in $G\in \mathcal{G}(n,p)$ is ${n \choose k}k^{k-2}p^{k-1}$.
\end{sol}


\begin{hw}
Show that, for constant $p\in(0,1)$, almost no graph in $\mathcal{G}(n,p)$ has a separating complete subgraph.
\end{hw}
\begin{sol}
	Let $X$ be a separating subgraph of $G$ and assume $X$ separates two vertices $u$ and $v$, then for any vertex $w\in V$, if $(u,w) \in E$ and $(w,v) \in E$, we have $w \in X, (u,w) \in X$ and $(w,v) \in X$. As $n$ approches $\infty$, the number of vertices in $X$ will also approaches $\infty$. $X$ is also a random graph, thus it has the property $P_{i,j}$, so it can not be a complete graph.
\end{sol}


\begin{hw}
Show that if almost all $G\in \mathcal{G}(n,p)$ have a graph property $\mathcal{P}_1$ and almost all $G\in \mathcal{G}(n,p)$ have a graph property $\mathcal{P}_2$, then almost all $G\in \mathcal{G}(n,p)$ have both properties.
\end{hw}
\begin{sol}
	By definition, we know that the probability that $G$ dose not have the property $\mathcal{P}_1$ tends to be $0$ as $n$ approaches $\infty$, the same for $\mathcal{P}_2$. Thus, the probability that $G$ has neither of the two properties tends to be $0$ as $n$ approaches $\infty$. The probability that $G$ has both properties equals $1$ minus the probability that $G$ has neither of the two properties, thus it will tend to be $1$ as $n$ approaches $\infty$.
\end{sol}




\begin{hw}
Consider $\mathbf{G}(n,p)$ with $p=\frac{1}{3n}$.
\begin{enumerate}
  \item Use the second moment method to show that with high probability there exists a simple path of length 10.
 % \item Argue that on the other hand, it is unlikely there exists any cycle of length 10.
\end{enumerate}
\end{hw}
\begin{sol}
	For any two different vertices $i$ and $j$, we define
	\begin{displaymath}
		I_{ij} = \left\{
			\begin{array}{ll}
			1 & if\ there\ exists\ a\ path\ of\ length\ 10\ between\ i\ and\ j \\
			0 & otherwise
			\end{array}
		\right.
	\end{displaymath}
	Let $x = \sum_{i < j}I_{ij}$, then we have
	\begin{displaymath}
	\begin{array}{lcl}
		E(x^{2}) & = & E(\sum_{i < j}I_{ij} \cdot \sum_{i < j}I_{ij}) \\
				 & = & E(\sum_{i < j}I_{ij} \cdot \sum_{k < l}I_{kl}) \\
				 & = & \sum_{i < j,k < l}E(I_{ij}I_{kl}) \\
				 & = & \sum_{i < j,k < l}E(I_{ij}I_{kl}) + \sum_{\{i,j,k\},i<j}E(I_{ij}I_{ik}) + \sum_{i < j}E(I_{ij}^{2}) \\
				 & = & {n \choose 4}\left( 9! {n-2 \choose 9} p^{10}\right)^{2} + {n \choose 3}\left( 9! {n-2 \choose 9} p^{10}\right)^{2} + {n \choose 2}\left( 9! {n-2 \choose 9} p^{10}\right)
	\end{array}
	\end{displaymath}
	and $E(x)= E(\sum_{i < j}I_{ij}) = \sum_{i < j}E(I_{ij}) = 9! {n \choose 2}{n-2 \choose 9} p^{10}$. Thus, $E^{2}(x)= \left( 9! {n \choose 2}{n-2 \choose 9} p^{10}\right)^{2}$ and we have $E(x^{2}) \le E^{2}(x)(1+o(1))$. By second moment method, we know that with high probability there exists a simple path of length 10.
\end{sol}

\begin{hw}(Optional)

\begin{enumerate}

\item Prove that the threshold for the existence of cycles in $\mathcal{G}(n,p)$ is $p=\frac{1}{n}$.
\item Search the \emph{World Wide Web} to find some real world graphs in machine readable form or data bases that could automatically be converted to graphs.

\begin{enumerate}
  \item Plot the degree distribution of each graph.
  \item Compute the average degree of each graph.
  \item Count the number of connected components of each size in each graph.
  \item Describe what you find.
\end{enumerate}
\item Create a simulation (an animation) to  show the evolution of the $\mathcal{G}(n,p)$ (Erd\"{o}s-R\'{e}nyi) random graph as its density $p$ is gradually increased. Observe the phase transitions for trees of increasing orders, followed by the emergence of the giant component, etc.
\end{enumerate}
\end{hw}
%\begin{sol}
	%\begin{enumerate}
	%	\item Let $x$ be the number of cycles in $G(n,p)$. Since there are ${n \choose k}\frac{(k-1)!}{2}$ possible cycles of length k, thus,
	%	$$E(x) = \sum_{k = 3}^{n}{n \choose k}\frac{(k-1)!}{2}p^{k} \le \sum_{k=3}^{n}\frac{n^{k}}{2k}p^{k} \le \sum_{k=3}^{n}(np)^{k}$$
	%	If $p = o(\frac{1}{n})$, then $\lim_{n \rightarrow \infty}(np) = 0$ and $\lim_{n \rightarrow \infty}\sum_{k=3}^{n}(np)^{k} = 0$. So, as n goes to infinity, $E(x)$ goes to zero, thus by the first moment method, almost all graphs have no cycles.
%	\end{enumerate}
%\end{sol}



\begin{hw} (Optional)

Prove that `the disappearance of isolated vertices in $\mathbf{G}(n,p)$' has a sharp threshold of $\frac{\ln n}{n}$.
\end{hw}
\begin{proof}
	We define that 
	\begin{displaymath}
		I_i = \left\{
			\begin{array}{ll}
				1 & \textrm{if}\ v_i\ \textrm{is an isolated vertex} \\
				0 & \textrm{else}
			\end{array}
			\right.
	\end{displaymath}
	Let $x = \sum_{i = 1}^{n}I_i$, by the linearity of expectation, we have $E(x) = n(1-p)^{n-1}$. Since we believe the threshold to be $\frac{\ln n}{n}$, consider $p = c\frac{\ln n}{n}$. Then, we have $$\lim_{n \rightarrow \infty}E(x) = \lim_{n \rightarrow \infty}n(1 - c\frac{\ln n}{n})^{n} = \lim_{n \rightarrow \infty}ne^{-c \ln n} = \lim_{n \rightarrow \infty}n^{1-c}$$ If $c > 1$, $E(x)$ tends to go to zero as n approaches infinity. By the first moment method, we have that almost all graphs have no isolated vertices. On the other hand, if $c < 1$, we have $E(x^2) = E(\sum_{i = 1}^{n}I_i \cdot \sum_{i = 1}^{n}I_i) = \sum_{i=1}^{n}E(I_{i}^{2}) + 2\sum_{i < j}E(I_{i}I_{j})$. Since $I_{i}$ equals $0$ or $1$, $I_{i}^{2} = I_{i}$, thus we have $$E(x^2) = E(x) + n(n-1)E(I_{i}I_{j}) = E(x) + n(n-1)(1-p)^{2(n-1)-1}$$.
	$$ \frac{E(x^2)}{E^{2}(x)} = \frac{n(1-p)^{n-1} + n(n-1)(1-p)^{2(n-1)-1}}{n^{2}(1-p)^{2(n-1)}} = \frac{1}{n(1-p)^{n-1}} + \left(1 - \frac{1}{n}\right)\frac{1}{1-p}$$
	For $p = c\frac{\ln n}{n}$ with $c < 1$, we have $\lim_{n \rightarrow \infty}\frac{E(x^2)}{E^{2}(x)} = 1 + o(1)$, thus by the second moment method, we have that almost all graphs have an isolated vertex. Thus, $\frac{\ln n}{n}$ is a sharp threshold
	for the disappearance of isolated vertices.
\end{proof}


\end{document}

%%% Local Variables:
%%% mode: tex-pdf
%%% TeX-master: t
%%% End:
